# Day 06 – Neural Network From Scratch

## Project Overview
This project implements a simple feedforward neural network with one hidden layer
using pure Python.

The goal is to understand how neural networks learn using backpropagation.

---

## Objective
To perform binary classification using a neural network trained with gradient descent.

---

## Network Architecture
Input → Hidden Layer (1 neuron) → Output Layer (1 neuron)

Activation function:
Sigmoid

Loss function:
Mean Squared Error

---

## Implementation Details
1. Generated synthetic data
2. Initialized weights randomly
3. Performed forward propagation
4. Computed loss
5. Applied backpropagation
6. Updated weights
7. Observed loss reduction

---

## Output
The script prints:
- Loss during training
- Final predictions

---

## Why This Matters
- Core of deep learning
- Used in image recognition
- Used in NLP models
- Foundation of modern AI

---

## How to Run
```bash
python neural_network.py
